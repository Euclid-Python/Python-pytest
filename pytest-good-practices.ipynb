{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some good practices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "import ipytest\n",
    "\n",
    "ipytest.config(rewrite_asserts=True, magics=True)\n",
    "\n",
    "__file__ = 'pytest-good-practices.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using `Computer` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Computer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.total = 0\n",
    "        \n",
    "    def add(self,a):\n",
    "        self.total = self.total + a\n",
    "        return self.total\n",
    "    \n",
    "    def substract(self,a):\n",
    "        self.total = self.total - a\n",
    "        return self.total\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Put Ever a `conftest.py` file\n",
    "\n",
    "This file permits to pytest to get preferences and to understand **where** is the root of the project.\n",
    "\n",
    "If using `pytest` directly you get a *module not found* error, because of a problem about the rooot of project, try to put a configtest.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Give meaningful name to test functions\n",
    "\n",
    "The rule is to not waste time on searching what is a test failure about \n",
    "\n",
    "* Avoid names as `test_1`, `test_foo`\n",
    "* Use *SnakeCase* to create **phrases** as \n",
    "  * *Send a rocket when it's raining* &rarr; `test_send_rocket_when_raining`\n",
    "  * *Send a rocket when it's raining_but_hot* &rarr; `test_send_rocket_when_raining_but_hot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Make test fail first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b><span style=\"font-size:larger;\">FAIL</span></b> the test  <b><span style=\"font-size:larger;\">FIRST</span></b>.\n",
    "</div>\n",
    "\n",
    "A test that has **always** passed is <span style=\"font-size: larger;\"><b>misleading</b></span>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -qq\n",
    "\n",
    "def test_substract():\n",
    "    computer = Computer()\n",
    "    computer.substract(1)\n",
    "    assert computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Modify the `Computer` class to make the test **fail**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Computer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.total = 0\n",
    "        \n",
    "    def add(self,a):\n",
    "        self.total = self.total + a\n",
    "        return self.total\n",
    "    \n",
    "    def substract(self,a):\n",
    "        #--------------------------------------\n",
    "        #self.total = self.total - a\n",
    "        self.total = self.total \n",
    "        #---------------------------------------\n",
    "        return self.total\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -qq\n",
    "\n",
    "def test_substract():\n",
    "    computer = Computer()\n",
    "    computer.substract(1)\n",
    "    assert computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one passed but it's **wrong**, it would be always sucessful.\n",
    "\n",
    "The assertion doesn't test an expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "_Wrong_\n",
    "```python\n",
    "assert computer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "_Right_\n",
    "```python\n",
    "assert computer.total == -1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Correct the test to check the actual excpectations. \n",
    "\n",
    "```python\n",
    "assert computer.total == -1\n",
    "```\n",
    "\n",
    "The test must fail **as the code under test is designed to fail**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -qq\n",
    "\n",
    "def test_substract():\n",
    "    computer = Computer()\n",
    "    computer.substract(1)\n",
    "    assert computer.total == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Correct the *Code Under test* to make test pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Computer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.total = 0\n",
    "        \n",
    "    def add(self,a):\n",
    "        self.total = self.total + a\n",
    "        return self.total\n",
    "    \n",
    "    def substract(self,a):\n",
    "        self.total = self.total - a\n",
    "        return self.total\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -qq\n",
    "\n",
    "def test_substract():\n",
    "    computer = Computer()\n",
    "    computer.substract(1)\n",
    "    assert computer.total == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know that the test is **one** of the real witnesses of `Computer.add(int)` correct processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b><span style=\"font-size:larger;\">FAIL</span></b> the test  <b><span style=\"font-size:larger;\">FIRST</span></b>.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "<img src=\"images/pytest-lifecycle.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test expectation must be observable\n",
    "\n",
    "A test expectation must be observable from a external point of view.\n",
    "\n",
    "A test where action implies nothing visible has no interest nor meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can bot easily constate effects of a action, your design is bad.\n",
    "\n",
    "Please <span style=\"font-size: larger;\">Reconsider your design</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Test Driven Development is a development ***philosph?*** emphasing Test Writting first.\n",
    "\n",
    "Test is a descrition of an expected behavior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/pytest-tdd-lifecycle.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bugfix\n",
    "\n",
    "When a bug is identified, creates a unit test to reproduce it, **then** fix the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/pytest-bugfix-lifecycle.png\"/>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
